{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabilLearns/Deeply-Supervised-Nets/blob/master/DSN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC2x6nlsnjls"
      },
      "source": [
        "## Get required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVZlv2uunjlx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsrIDxkYnjlz"
      },
      "outputs": [],
      "source": [
        "!pip --quiet install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JE61fHqnjl1",
        "outputId": "1b08cf5d-4627-4990-cc09-543c006450f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/nabil/Documents/Code/Data_Classification\n",
            "/home/nabil/Documents/Code/Data_Classification/DateData\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "#os.path.join(os.getcwd()\n",
        "print(os.getcwd())\n",
        "print(os.path.join(os.getcwd(), 'DateData'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFCHTQu2njl3"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhXkGT4Mnjl4"
      },
      "outputs": [],
      "source": [
        "# Download dataset in an .arff final into current working directory\n",
        "\n",
        "import wget, requests, io, os, shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "data_url = \"https://www.muratkoklu.com/datasets/vtdhnd06.php\"\n",
        "req = requests.get(data_url)\n",
        "zip_file = ZipFile(io.BytesIO(req.content))\n",
        "path = os.path.join(os.getcwd())\n",
        "zip_file.extractall(path)\n",
        "\n",
        "shutil.move(os.path.join(os.getcwd(),'Date_Fruit_Datasets/Date_Fruit_Datasets.arff'), os.path.join(os.getcwd(), 'Date_Fruit_Datasets.arff'))\n",
        "shutil.rmtree(os.path.join(os.getcwd(),'Date_Fruit_Datasets'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89ypVo3Vnjl6",
        "outputId": "7cad930a-26d0-4d1a-d7a8-00e6f7e07ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Date_Fruit_Datasets.arff']\n"
          ]
        }
      ],
      "source": [
        "# Python script that converts .arff to .csv (not mine)\n",
        "# Source: https://github.com/haloboy777/arfftocsv/blob/master/arffToCsv.py\n",
        "\n",
        "#########################################\n",
        "# Project   : ARFF to CSV converter     #\n",
        "# Created   : 10/01/17 11:08:06         #\n",
        "# Author    : haloboy777                #\n",
        "# Licence   : MIT                       #\n",
        "#########################################\n",
        "\n",
        "# Importing library\n",
        "import os\n",
        "\n",
        "# Getting all the arff files from the current directory\n",
        "files = [arff for arff in os.listdir('.') if arff.endswith(\".arff\")]\n",
        "print(files)\n",
        "\n",
        "# Function for converting arff list to csv list\n",
        "def toCsv(text):\n",
        "    data = False\n",
        "    header = \"\"\n",
        "    new_content = []\n",
        "    for line in text:\n",
        "        if not data:\n",
        "            if \"@ATTRIBUTE\" in line or \"@attribute\" in line:\n",
        "                attributes = line.split()\n",
        "                if(\"@attribute\" in line):\n",
        "                    attri_case = \"@attribute\"\n",
        "                else:\n",
        "                    attri_case = \"@ATTRIBUTE\"\n",
        "                column_name = attributes[attributes.index(attri_case) + 1]\n",
        "                header = header + column_name + \",\"\n",
        "            elif \"@DATA\" in line or \"@data\" in line:\n",
        "                data = True\n",
        "                header = header[:-1]\n",
        "                header += '\\n'\n",
        "                new_content.append(header)\n",
        "        else:\n",
        "            new_content.append(line)\n",
        "    return new_content\n",
        "\n",
        "\n",
        "# Main loop for reading and writing files\n",
        "for file in files:\n",
        "    with open(file, \"r\") as inFile:\n",
        "        content = inFile.readlines()\n",
        "        name, ext = os.path.splitext(inFile.name)\n",
        "        new = toCsv(content)\n",
        "        with open(name + \".csv\", \"w\") as outFile:\n",
        "            outFile.writelines(new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXAFFs1fnjl8"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPWtiFvPnjl9",
        "outputId": "368a4c88-1509-459f-b106-11c28da1c905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
            "0  422163   2378.908    837.8484    645.6693        0.6373  733.1539   \n",
            "1  338136   2085.144    723.8198    595.2073        0.5690  656.1464   \n",
            "2  526843   2647.394    940.7379    715.3638        0.6494  819.0222   \n",
            "3  416063   2351.210    827.9804    645.2988        0.6266  727.8378   \n",
            "4  347562   2160.354    763.9877    582.8359        0.6465  665.2291   \n",
            "\n",
            "   SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n",
            "0    0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n",
            "1    0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n",
            "2    0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n",
            "3    0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n",
            "4    0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n",
            "\n",
            "   KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  ALLdaub4RG  \\\n",
            "0      4.2287 -59191263232 -50714214400 -39922372608     58.7255     54.9554   \n",
            "1      3.1704 -34233065472 -37462601728 -31477794816     50.0259     52.8168   \n",
            "2      4.7192 -93948354560 -74738221056 -60311207936     65.4772     59.2860   \n",
            "3      8.2618 -32074307584 -32060925952 -29575010304     43.3900     44.1259   \n",
            "4      4.4146 -39980974080 -35980042240 -25593278464     52.7743     50.9080   \n",
            "\n",
            "   ALLdaub4RB  Class  \n",
            "0     47.8400  BERHI  \n",
            "1     47.8315  BERHI  \n",
            "2     51.9378  BERHI  \n",
            "3     41.1882  BERHI  \n",
            "4     42.6666  BERHI  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"Date_Fruit_Datasets.csv\")\n",
        "print(data.head())\n",
        "\n",
        "# As you can see, the values need to be normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp4OkakQnjl_"
      },
      "source": [
        "### Generate train/val/test data splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5_JtFnXnjmA",
        "outputId": "7daa81b3-86ea-4492-f507-8862e1b1a5dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
            "0    1.154996   0.783506    0.604171    1.310912     -1.128939  1.075105   \n",
            "1    0.371493   0.067030   -0.187369    0.869305     -1.898713  0.431196   \n",
            "2    2.131077   1.438330    1.318387    1.920829     -0.992566  1.793104   \n",
            "3    1.098117   0.715952    0.535671    1.307670     -1.249533  1.030654   \n",
            "4    0.459385   0.250463    0.091460    0.761039     -1.025251  0.507143   \n",
            "..        ...        ...         ...         ...           ...       ...   \n",
            "893 -0.399945  -0.322663   -0.409322   -0.163589     -0.150662 -0.287007   \n",
            "894  0.630600   1.480838    0.726446    0.487201      0.303539  0.652184   \n",
            "895 -0.409950  -0.319319   -0.023030   -0.527273      0.846776 -0.297034   \n",
            "896 -0.553313  -0.369240   -0.237149   -0.472947      0.561632 -0.443100   \n",
            "897  0.424231   0.564888    0.506956    0.340451      0.261838  0.476892   \n",
            "\n",
            "     SOLIDITY  CONVEX_AREA    EXTENT  ASPECT_RATIO  ...  KurtosisRR  \\\n",
            "0    0.708233     1.108135  0.871387     -0.046771  ...   -0.349488   \n",
            "1    0.856933     0.323193  0.804404     -0.051345  ...   -0.561841   \n",
            "2    0.790844     2.067997  0.547637     -0.045795  ...   -0.171571   \n",
            "3    0.713741     1.051406  0.737421     -0.047585  ...    0.273913   \n",
            "4    0.493445     0.431477  0.383901     -0.046031  ...   -0.534597   \n",
            "..        ...          ...       ...           ...  ...         ...   \n",
            "893 -0.183964    -0.393487 -0.174288     -0.038225  ...   -0.693395   \n",
            "894 -1.940822     0.760188 -1.242291     -0.032552  ...   -0.289364   \n",
            "895  0.587071    -0.437351 -0.228246     -0.023299  ...   -0.681778   \n",
            "896 -1.180802    -0.505907 -0.760387     -0.028568  ...   -0.543137   \n",
            "897 -0.205994     0.437680 -0.784575     -0.033141  ...   -0.599527   \n",
            "\n",
            "     KurtosisRG  KurtosisRB  EntropyRR  EntropyRG  EntropyRB  ALLdaub4RR  \\\n",
            "0     -0.574961    0.218443  -1.342063  -1.266563  -0.822269    0.538041   \n",
            "1     -0.661038   -0.297843  -0.116965  -0.492950  -0.253281   -0.003548   \n",
            "2     -0.333682    0.457731  -3.048149  -2.669054  -2.196053    0.958363   \n",
            "3      0.935186    2.185971  -0.011000  -0.177607  -0.125072   -0.416662   \n",
            "4     -0.569968    0.309134  -0.399107  -0.406400   0.143213    0.167552   \n",
            "..          ...         ...        ...        ...        ...         ...   \n",
            "893   -0.731684   -0.517471   0.321699   0.575014   0.622946   -0.062005   \n",
            "894   -0.408600    0.102483   0.012025   0.412926   0.568738   -0.203839   \n",
            "895   -0.694679   -0.529716   0.471590   0.550142   0.682323   -0.370438   \n",
            "896   -0.647048   -0.478980   0.284778   0.450613   0.532888    0.071207   \n",
            "897   -0.553735   -0.338773  -0.006542   0.498326   0.437925   -0.170421   \n",
            "\n",
            "     ALLdaub4RG  ALLdaub4RB     Class  \n",
            "0      0.435350   -0.023895 -1.818025  \n",
            "1      0.283955   -0.024681 -1.818025  \n",
            "2      0.741922    0.355045 -1.818025  \n",
            "3     -0.331291   -0.639012 -1.818025  \n",
            "4      0.148827   -0.502299 -1.818025  \n",
            "..          ...         ...       ...  \n",
            "893   -0.408008   -0.525538  1.508127  \n",
            "894   -0.686758   -1.067906  1.508127  \n",
            "895   -0.566836   -0.658552  1.508127  \n",
            "896   -0.218710   -0.228632  1.508127  \n",
            "897   -0.715641   -0.779055  1.508127  \n",
            "\n",
            "[898 rows x 35 columns]\n",
            "[1 2 3 4 5 6 7]\n",
            "<class 'pandas.core.frame.DataFrame'> (52, 35)\n",
            "<class 'pandas.core.frame.DataFrame'> (78, 35)\n",
            "<class 'pandas.core.frame.DataFrame'> (163, 35)\n",
            "<class 'pandas.core.frame.DataFrame'> (57, 35)\n",
            "<class 'pandas.core.frame.DataFrame'> (132, 35)\n",
            "<class 'pandas.core.frame.DataFrame'> (159, 35)\n",
            "<class 'pandas.core.frame.DataFrame'> (75, 35)\n"
          ]
        }
      ],
      "source": [
        "# Generate train/val/test data splits\n",
        "\n",
        "#print(data.info())\n",
        "#print(data['Class'].unique())\n",
        "#normalized_df=(df-df.mean())/df.std()\n",
        "\n",
        "normalized = (data - data.mean()) / data.std()\n",
        "data = normalized\n",
        "print(normalized)\n",
        "\n",
        "data['Class'] = data['Class'].astype('category').cat.codes + 1\n",
        "print(data['Class'].unique())\n",
        "train, val, test = {}, {}, {}\n",
        "for date_type in data['Class'].unique(): #['DOKOL']\n",
        "\n",
        "    num_examples = data[data['Class'] == date_type].shape[0]\n",
        "    data[data['Class'] == date_type] = data[data['Class'] == date_type].sample(frac=1, random_state=42)\n",
        "\n",
        "    train[date_type] = data[data['Class'] == date_type].reset_index().drop(columns=['index']).iloc[0:int(num_examples*0.8)]#.values\n",
        "    val[date_type] = data[data['Class'] == date_type].reset_index().drop(columns=['index']).iloc[int(num_examples*0.8):int(num_examples*0.9)]#.values\n",
        "    test[date_type] = data[data['Class'] == date_type].reset_index().drop(columns=['index']).iloc[int(num_examples*0.9):]#.values\n",
        "\n",
        "    print(type(train[date_type]), train[date_type].shape)\n",
        "\n",
        "#print(len(train))\n",
        "train, val, test = [pd.concat(split).sample(frac=1, random_state=1).reset_index(drop=True) for split in [train, val, test]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx_bkn9mnjmB"
      },
      "source": [
        "### Get data and label tensors from each dataframe split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkzOwfe5njmB"
      },
      "outputs": [],
      "source": [
        "# Get data and label tensors from each split dataframe\n",
        "\n",
        "X_train = torch.Tensor(train.values[:,:-1])\n",
        "Y_train = torch.Tensor(train.values[:,-1])\n",
        "\n",
        "X_val = torch.Tensor(val.values[:,:-1])\n",
        "Y_val = torch.Tensor(val.values[:,-1])\n",
        "\n",
        "X_test = torch.Tensor(test.values[:,:-1])\n",
        "Y_test = torch.Tensor(test.values[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibMKTrBFnjmC",
        "outputId": "4a5a218a-9eb1-4fa7-eb07-c5bda24baf1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6., 7.])\n"
          ]
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUCBVAIRnjmD"
      },
      "source": [
        "## Define Model Architecture and Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGbWcYCanjmD"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, n_in=34, n_hidden=5, n_classes=7):#, ks, stride):\n",
        "        super(Network, self).__init__()\n",
        "        self.mapping1 = nn.Linear(n_in, n_hidden)\n",
        "        self.mapping2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.mapping3 = nn.Linear(n_hidden, n_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.svm_1 = torch.empty(n_hidden)\n",
        "        nn.init.uniform_(self.svm_1, -0.01, 0.02)\n",
        "\n",
        "        self.svm_2 = torch.empty(n_hidden)\n",
        "        nn.init.normal_(self.svm_2, -0.01, 0.02)\n",
        "\n",
        "        self.svm_3 = torch.empty(n_classes)\n",
        "        nn.init.normal_(self.svm_3, -0.01, 0.02)\n",
        "\n",
        "        #self.w = nn.Parameter(torch.randn(1, 2), requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        f_map1 = self.relu(self.mapping1(x))\n",
        "        f_map2 = self.relu(self.mapping2(f_map1))\n",
        "        f_map3 = self.mapping3(f_map2)\n",
        "                \n",
        "        return [f_map1, f_map2, f_map3, self.svm_1, self.svm_2, self.svm_3]\n",
        "\n",
        "\n",
        "def companion_loss(f_map, svm_w, t_labels, n_labels=7):\n",
        "    \"\"\"\n",
        "    Implements L2-SVM companion objective loss described by equations (4) and (5) of the \"Deeply Supervised Nets\" paper ([Gallagher et. al, 2014])\n",
        "\n",
        "    parameters\n",
        "    ----------\n",
        "    f_map: of shape (BATCH_SIZE x NUM_FEATURES)\n",
        "    svm_w: svm weights\n",
        "    t_labels: vector of labels\n",
        "    \"\"\"\n",
        "\n",
        "    loss = 0\n",
        "    all_labels = torch.arange(n_labels) + 1\n",
        "\n",
        "    f_labels = [all_labels[all_labels != t_labels[i]] for i in range(len(t_labels))] # f_labels.shape = (# examples, 6), each row has labels != t_label\n",
        "    f_labels = torch.stack(f_labels)\n",
        "\n",
        "    #print(f_map.shape, svm_w.shape, (f_map@svm_w).shape)\n",
        "    svm_pred = torch.unsqueeze(f_map @ svm_w, dim=0).T # torch.Size([716, 1])\n",
        "\n",
        "    # < w^(m), (Z^(m), y) >\n",
        "    true_label_svm = svm_pred * torch.unsqueeze(t_labels,dim=0).T # torch.Size([716, 1])\n",
        "    \n",
        "    # < w^(m), (Z^(m), y_k) > for all k\n",
        "    f_labels_svm = svm_pred * f_labels # torch.Size([716, 6])\n",
        "\n",
        "    #print(svm_pred.shape, true_label_svm.shape, f_labels_svm.shape, f_labels.shape)\n",
        "\n",
        "    loss = torch.sum(torch.nn.functional.relu(1 - (true_label_svm - f_labels_svm))**2)#**2\n",
        "    \n",
        "    return loss\n",
        "\n",
        "#global_loss = lambda data: torch.sum([companion_loss(f_map) for f_map in Network(data)])\n",
        "def global_loss(model_out: list, Y, alphas: list, gamma = 0.05):\n",
        "    \"\"\"\n",
        "    Return overall combined objective function as specified in eq. (3) of [Gallagher et. al, 2014]\n",
        "    \n",
        "    parameters\n",
        "    ----------\n",
        "    model_out: [f_map1, f_map2, f_map3, svm1, svm2, svm3]\n",
        "    alphas: list of alpha values (see eq. (3), and pg. 4 of [Gallagher et. al, 2014])\n",
        "    gamma: see pg. 4 of [Gallagher et. al, 2014]\n",
        "    \"\"\"\n",
        "\n",
        "    n_layers = len(model_out) // 2\n",
        "    companion_losses = [companion_loss(model_out[m], model_out[m+n_layers], Y) for m in range(n_layers)]\n",
        "    \n",
        "    f_layer_loss = torch.norm(model_out[-1])**2 + companion_losses[-1]\n",
        "    modified_companion_losses = [alphas[m] * torch.nn.functional.relu(torch.norm(model_out[m + n_layers])**2 + companion_losses[m] - gamma) for m in range(n_layers - 1)]\n",
        "    global_loss = f_layer_loss + sum(modified_companion_losses)\n",
        "    \n",
        "    #print(companion_losses)\n",
        "    #print(\"norms: \", torch.norm(model_out[-1]), torch.norm(model_out[-2]))\n",
        "    return global_loss\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc5zXLg0njmE"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH_lZlkYnjmE"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs = 100):\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.01)\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "\n",
        "    alphas = [0.1, 0.1]#[14, 10]\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        avg_train_loss = 0\n",
        "        train_acc = 0\n",
        "\n",
        "        if epoch % (int)(num_epochs * 0.2) == 0:\n",
        "            print(f\"EPOCH {epoch}\")\n",
        "            #print(torch.nn.functional.softmax(model(X_train)[1][0:10],dim=1))\n",
        "            print(torch.argmax(model(X_train)[2][0:10],dim=1))\n",
        "\n",
        "        batch_sz = 125\n",
        "        alphas = [a * 0.1 * (1 - epoch / num_epochs) for a in alphas]\n",
        "        \n",
        "        for batch_idx in range(0, X_train.shape[0], batch_sz):\n",
        "            opt.zero_grad()\n",
        "            L = global_loss(model(X_train[batch_idx:batch_idx+batch_sz]), Y_train[batch_idx:batch_idx+batch_sz], alphas)\n",
        "            L.backward()\n",
        "            opt.step()\n",
        "\n",
        "            avg_train_loss += L.item()\n",
        "\n",
        "            train_batch_pred = torch.argmax(model(X_train[batch_idx:batch_idx+batch_sz])[2],dim=1) + 1\n",
        "            train_batch_true = Y_train[batch_idx:batch_idx+batch_sz]\n",
        "            train_acc += np.array(train_batch_pred == train_batch_true).sum()\n",
        "        \n",
        "        epoch_losses.append(avg_train_loss / X_train.shape[0])\n",
        "        epoch_accs.append(train_acc / X_train.shape[0])\n",
        "\n",
        "    plt.plot(epoch_losses)\n",
        "    plt.title(\"Train Set Loss\")\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch #')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epoch_accs)\n",
        "    plt.title(\"Train Set Accuracy\")\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch #')\n",
        "    plt.show()\n",
        "    \n",
        "    return epoch_losses, epoch_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fFRo6pTnjmF",
        "outputId": "1abac11f-0e39-437d-a08f-25e5a6cee943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 0\n",
            "tensor([6, 6, 6, 1, 6, 6, 1, 6, 6, 1])\n",
            "EPOCH 20\n",
            "tensor([1, 1, 6, 1, 6, 6, 1, 1, 6, 1])\n",
            "EPOCH 40\n",
            "tensor([1, 1, 6, 1, 1, 6, 1, 1, 6, 1])\n",
            "EPOCH 60\n",
            "tensor([1, 1, 6, 1, 1, 6, 1, 1, 6, 1])\n",
            "EPOCH 80\n",
            "tensor([1, 1, 6, 1, 1, 6, 1, 1, 6, 1])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAk60lEQVR4nO3deXRkdZ338fe3llSlsm+9pjtNQ7NrI4RdEFBRdsdxQUHBwWEQHHHGR0cfn+My4/icmTPjAijIKorAzKOiDCAi+yZLN9vQdANN0003vSTpdPatknyfP+qGCSHdnXRSqVTdz+ucOqm691bd748O9cnv97uLuTsiIhJekVwXICIiuaUgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQSOiY2R/M7Lxc1yEyWygIJC+YWdeox7CZ9Y56fc5kPsvdT3H3G/ewjvea2eNm1m5mrWb2mJkdPsH3upnts4v155vZo3tSl8hUxHJdgMhEuHvpyHMzWw983t3vHbudmcXcfTAbNZhZOXAH8AXgP4Ei4DigPxv7E5kp6hFIXjOzE8xsk5n9g5ltBW4wsyozu8PMms1sR/C8ftR7HjSzzwfPzzezR83s34JtXzezU3ayu30B3P0Wdx9y9153v8fdXxj12X9lZquDz/qjmTUEyx8ONnk+6MV8cpLtPMbMng56Ik+b2TGj1p1vZuvMrDOo/5xg+T5m9lDwnhYz+4/J7FPCQ0EghWAeUA00ABeS+b2+IXi9GOgFrtjF+48EXgZqgX8FrjMzG2e7V4AhM7vRzE4xs6rRK83sI8D/Bj4K1AGPALcAuPvxwWbL3b3U3Sf8pWxm1cCdwGVADfAD4E4zqzGzkmD5Ke5eBhwDPBe89Z+Ae4AqoB64fKL7lHBREEghGAa+7e79wV/p2939N+7e4+6dwD8D79vF+ze4+zXuPgTcCMwH5o7dyN07gPcCDlwDNJvZ7WY2su3fAP/X3VcHw1PfBw4Z6RVMwWnAq+7+S3cfdPdbgDXAGaPaf7CZFbv7FndfFSxPkwnDBe7e5+6af5BxKQikEDS7e9/ICzNLmdnPzGyDmXUADwOVZhbdyfu3jjxx957gael4GwZf8ue7ez1wMLAA+FGwugH4sZm1mVkb0AoYsHDPmwbBPjaMWbYBWOju3cAngYuALWZ2p5ntH2zztWD/T5nZKjP7qynWIQVKQSCFYOwldL8C7Acc6e7lwMiwzHjDPXu+U/c1wM/JBALARuBv3L1y1KPY3R+f4q42kwmZ0RYDbwZ1/NHdP0imJ7OGTG8Fd9/q7n/t7gvI9FZ+uqujliS8FARSiMrIzAu0BePr356ODzWz/c3sKyMTz2a2CPgU8ESwyVXAN8zsoGB9hZl9fNRHbAOW7n43lhz9AO4C9jWzT5tZLJhoPhC4w8zmmtmZwVxBP9AFDAUf9PFRk+Q7yATm0BT/M0gBUhBIIfoRUAy0kPmSvnuaPreTzMTyk2bWHXz2i2R6ILj7bcC/ALcGQ1IvAqOPQPoOcGMwdPSJnezjGDIhNvrRDpwe7Gc7mSGf0929hcz/w18h02toJTMXcnHwWYcHtXYBtwOXuvvrU/xvIAXIdGMaEZFwU49ARCTkFAQiIiGnIBARCTkFgYhIyOXdRedqa2t9yZIluS5DRCSvrFy5ssXd68Zbl3dBsGTJElasWJHrMkRE8oqZjT07/S0aGhIRCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5EITBK9s6+R7d7xEX1qXYxcRGS00QbBpRw/XPvo6z2zYketSRERmldAEwRF71RCLGI+91pLrUkREZpXQBEFpIsbyRZU8tnZ7rksREZlVQhMEAMfsXcMLm9ro6EvnuhQRkVkjZEFQy7DDk+tac12KiMisEaogOLShkmQ8wmNrNU8gIjIiVEGQiEU5fEk1j2vCWETkLaEKAsgMD72yrYumzr5clyIiMiuEMAhqAPjzazp6SEQEshwEZlZpZr82szVmttrMjh6z3szsMjNba2YvmNmh2awH4OCFFZQnYzyuw0hFRIDs36ryx8Dd7v4xMysCUmPWnwIsCx5HAlcGP7MmGjGOWlqjE8tERAJZ6xGYWTlwPHAdgLsPuHvbmM3OAn7hGU8AlWY2P1s1jTh2n1o27ejl9ZbubO9KRGTWy+bQ0FKgGbjBzJ41s2vNrGTMNguBjaNebwqWvY2ZXWhmK8xsRXNz85QL++CBcymKRvjJA2un/FkiIvkum0EQAw4FrnT39wDdwNfHbGPjvM/fscD9andvdPfGurq6KRe2oLKY849dwm+e2cSqze1T/jwRkXyWzSDYBGxy9yeD178mEwxjt1k06nU9sDmLNb3lkhP3obI4zj/fuRr3d2SPiEhoZC0I3H0rsNHM9gsWvR94acxmtwOfDY4eOgpod/ct2apptIriOJe+fxmPv7ad+9c0zcQuRURmpWyfR/C3wK/M7AXgEOD7ZnaRmV0UrL8LWAesBa4BLs5yPW9zzlEN7FVbwvfvWk16aHgmdy0iMmtk9fBRd38OaByz+KpR6x24JJs17Eo8GuHrp+zP3/xyJb9euYlPHbE4V6WIiORM6M4sHuvkA+eyvL6CnzywloFB9QpEJHxCHwRmxpc/sC+bdvTy22c25bocEZEZF/ogADhhvzqW11dwhXoFIhJCCgLUKxCRcFMQBEb3CnQEkYiEiYIgMLpXcNd/z8ipDCIis4KCYJQT9qujrizBn17alutSRERmjIJgFDPjhH3rePiVZgY1PCQiIaEgGOOE/ebQ0TfIcxvbcl2KiMiMUBCM8d5ltUQjxgMv6/pDIhIOCoIxKorjHLa4igdfnvp9D0RE8oGCYBwn7F/Hqs0dNHX05boUEZGsUxCM44R95wDw4CvqFYhI4VMQjOOA+WXMLU/woOYJRCQEFATjyBxGOodHXm3RWcYiUvAUBDtx4v51dPYN8syGHbkuRUQkqxQEO3HsPrUAPPV6a44rERHJLgXBTpQl48wrT7J+e0+uSxERySoFwS4srknxRmt3rssQEckqBcEuNFSn2KAegYgUOAXBLjTUpGjq7Kd3YCjXpYiIZI2CYBcW15QA8EaregUiUrgUBLvQUJ0CYMN2zROISOFSEOxCQ00mCNQjEJFCpiDYhcpUEeXJmCaMRaSgKQh2o6GmhA3qEYhIAVMQ7MbimhRvaI5ARAqYgmA3GqpTbNrRq3sYi0jBUhDsRkNNisFhZ0u7blIjIoVJQbAbi6sz5xJowlhEClVWg8DM1pvZf5vZc2a2Ypz1J5hZe7D+OTP7Vjbr2RMjh5Bu0DWHRKRAxWZgHye6e8su1j/i7qfPQB17ZF55kqJYhDfUIxCRAqWhod2IRIxFVcUaGhKRgpXtIHDgHjNbaWYX7mSbo83seTP7g5kdNN4GZnahma0wsxXNzTN/Q3mdSyAihSzbQXCsux8KnAJcYmbHj1n/DNDg7suBy4Hfjfch7n61uze6e2NdXV1WCx7P4urMuQTuPuP7FhHJtqwGgbtvDn42AbcBR4xZ3+HuXcHzu4C4mdVms6Y90VCTontgiJaugVyXIiIy7bIWBGZWYmZlI8+Bk4EXx2wzz8wseH5EUM/2bNW0p/7n4nM6ckhECk82jxqaC9wWfM/HgJvd/W4zuwjA3a8CPgZ8wcwGgV7gbJ+F4y+jzyU4rKE6x9WIiEyvrAWBu68Dlo+z/KpRz68ArshWDdNlUXUxZjqpTEQKkw4fnYBELEpNSYKmTl1mQkQKj4JggurKEjR39ue6DBGRaacgmKC6sgRNCgIRKUAKggmqK1WPQEQKk4JgguaUJ2jp6md4eNYd1CQiMiUKggmqK02QHnLae9O5LkVEZFopCCaoriwBQHOXhodEpLAoCCborSDQPIGIFBgFwQQpCESkUCkIJkhBICKFSkEwQWWJGIlYRGcXi0jBURBMkJkxp1znEohI4VEQTEJdaUJHDYlIwVEQTIKuNyQihUhBMAkKAhEpRAqCSagrTbKjJ83A4HCuSxERmTYKgkkYOYR0e7d6BSJSOBQEkzASBE0dCgIRKRwKgknQSWUiUogUBJMwRxeeE5ECpCCYhJrSIkA9AhEpLAqCSUjEolSm4goCESkoCoJJ0i0rRaTQKAgmqa5Ml5kQkcKiIJikurKErkAqIgVFQTBJI0ND7rqJvYgUBgXBJM0pT9CXHqarfzDXpYiITAsFwSTppDIRKTQKgkmqK00CCgIRKRwKgkmq09nFIlJgFASTpKEhESk0WQ0CM1tvZv9tZs+Z2Ypx1puZXWZma83sBTM7NJv1TIfK4jixiCkIRKRgxGZgHye6e8tO1p0CLAseRwJXBj9nrUjEqCtLsLVD5xKISGHI9dDQWcAvPOMJoNLM5ue4pt1aWFnMmzt6c12GiMi0mFAQmFmJmUWC5/ua2ZlmFp/AWx24x8xWmtmF46xfCGwc9XpTsGzs/i80sxVmtqK5uXkiJWfVouoUmxQEIlIgJtojeBhImtlC4D7gc8DPJ/C+Y939UDJDQJeY2fFj1ts473nHKbvufrW7N7p7Y11d3QRLzp76qmK2tPeSHtK9i0Uk/000CMzde4CPApe7+18AB+7uTe6+OfjZBNwGHDFmk03AolGv64HNE6wpZ+qrihl22NqueQIRyX8TDgIzOxo4B7gzWLbLieZgOKls5DlwMvDimM1uBz4bHD10FNDu7lsmXH2OLKpKAbBxR0+OKxERmbqJHjX0ZeAbwG3uvsrMlgIP7OY9c4HbzGxkPze7+91mdhGAu18F3AWcCqwFesgMOc169UEQbGrthb1zXIyIyBRNKAjc/SHgIYBg0rjF3b+0m/esA5aPs/yqUc8duGQyBc8G8yuTRAw2qUcgIgVgokcN3Wxm5cEQz0vAy2b21eyWNnvFoxHmVxTryCERKQgTnSM40N07gI+QGc5ZDHwmW0Xlg4VVxZojEJGCMNEgiAfnDXwE+L27pxnnMM8wWVSlcwlEpDBMNAh+BqwHSoCHzawB6MhWUfmgvqqYrR199A8O5boUEZEpmVAQuPtl7r7Q3U8NLgexATgxy7XNavVVxbjDljadSyAi+W2ik8UVZvaDkcs8mNm/k+kdhNai6uAQUg0PiUiem+jQ0PVAJ/CJ4NEB3JCtovJBfVUxoJPKRCT/TfSEsr3d/S9Hvf6umT2XhXryxrzyJLGI6VwCEcl7E+0R9JrZe0demNmxQKjHRGLRCPMrkxoaEpG8N9EewUXAL8ysIni9AzgvOyXlj/rKFBtb1SMQkfw20aOGnnf35cC7gXe7+3uAk7JaWR5YVK2zi0Uk/03qDmXu3hGcYQzw91moJ6/UV6Vo6uynL61zCUQkf03lVpXj3VQmVBZVZ44cerNNvQIRyV9TCYJQX2ICRl2OWsNDIpLHdndzmU7G/8I3oDgrFeWRkXMJdAipiOSzXQaBu5fNVCH5aG5ZknjU2NiqHoGI5K+pDA2FXiRiLKwsZn1Ld65LERHZYwqCKTp8STWPrm3RkUMikrcUBFN0+vIFdPUP8vArzbkuRURkjygIpuiYvWuoSsW544UtuS5FRGSPKAimKB6N8OGD53Hv6m0aHhKRvKQgmAanv3sBPQNDPLCmKdeliIhMmoJgGhy5VzU1JUUaHhKRvKQgmAaxaIRT3jWP+9Zso2dgMNfliIhMioJgmpz2rgX0pYe5b7WGh0QkvygIpskRe1VTV5bg1qffYHg49JdhEpE8oiCYJtGIcfEJe/PY2u386L5Xc12OiMiETfQOZTIB5x+zhJc2d3DZfa+ybE4pZyxfkOuSRER2Sz2CaWRmfO8vDqaxoYr/9f+e54VNbbkuSURktxQE0ywRi3LVZw6jtjTB397yLINDw7kuSURkl7IeBGYWNbNnzeyOcdadYGbtZvZc8PhWtuuZCbWlCb5z5kFs2N7D7c9vznU5IiK7NBM9gkuB1btY/4i7HxI8/nEG6pkRHzhgDvvPK+MnD6xlSEcRicgsltUgMLN64DTg2mzuZzYyM/72pGW81tzNH17UGcciMntlu0fwI+BrwK4Gyo82s+fN7A9mdtB4G5jZhWa2wsxWNDfnz+WeP3zwPPauK+GK+9fq3AIRmbWyFgRmdjrQ5O4rd7HZM0CDuy8HLgd+N95G7n61uze6e2NdXd30F5sl0YjxxZP2Yc3WTu5dvS3X5YiIjCubPYJjgTPNbD1wK3CSmd00egN373D3ruD5XUDczGqzWNOMO+PdC2ioSXHZ/a9qrkBEZqWsBYG7f8Pd6919CXA2cL+7nzt6GzObZ2YWPD8iqGd7tmrKhVg0wt9/cF9efLODm57YkOtyRETeYcbPIzCzi8zsouDlx4AXzex54DLgbHcvuD+bz1y+gOP3reNf717D5rbeXJcjIvI2lm/fu42Njb5ixYpclzFpG1t7OPmHD3PsPjVc89lGgo6QiMiMMLOV7t443jqdWTxDFlWn+PsP7su9q5v4w4tbc12OiMhbFAQz6HPHLuFdCyv41u9X0dzZn+tyREQABcGMikUj/NvHl9PVn+bL//GsjiISkVlBQTDD9ptXxj+eeTCPrd3O5ffrvgUiknsKghz4eGM9Hz10IT++71UeW9uS63JEJOQUBDlgZnzvIwezT10pl976LG/qkFIRySEFQY6kimJcee5h9A8Oc8HPn6arfzDXJYlISCkIcmifOaX89JxDebWpiy/dosljEckNBUGOHbesju+eeRD3r2nie3e+lOtyRCSEdPP6WeDcoxp4rbmLGx5bz7I5ZXz6yMW5LklEQkQ9glni/5x2IO/bt45v/f5FHn9NRxKJyMxREMwS0Yhx+affw5LaEi7+1TOsb+nOdUkiEhIKglmkPBnnuvMy14S64Manae9N57giEQkDBcEs01BTwpXnHMaG7T188eZnSA/t6i6fIiJTpyCYhY7eu4bvf/RdPPJqC9++fRX5dqlwEckvOmpolvpE4yJeb+nmygdfY2ltCZ8/bmmuSxKRAqUgmMW+evJ+rG/p5p/vWk19VTEfPnh+rksSkQKkoaFZLBIxfvCJQzhkUSWX3vocK9a35rokESlACoJZrrgoynXnHc6CymIuuHEFa5s6c12SiBQYBUEeqC4p4sbPHUE8apx3/dNs6+jLdUkiUkAUBHlicU2KG84/graeAT59zRO61aWITBsFQR55V30F159/OJvb+jj32idp7R7IdUkiUgAUBHnmyKU1XHteI69v7+Yz1z1Je4/OPhaRqVEQ5KFj96nlZ585jFe2dfLJq/9Mk+YMRGQKFAR56sT95nD9+YfzRmsPH73ycV7XRepEZA8pCPLYccvquOWvj6K7f5CPXfk4L2xqy3VJIpKHFAR5bvmiSn79hWNIxqN84md/5u4Xt+S6JBHJMwqCArB3XSm/u+RY9p9XzkU3PcOVD76mC9WJyIQpCApEXVmCWy88ijOWL+Bf7l7DV/7zeXoHhnJdlojkAV10roAk41EuO/sQls0p5Yf3vsKarZ387DOHsag6levSRGQWU4+gwJgZX3r/Mq4/73A27ujhjCse5ZFXm3NdlojMYlkPAjOLmtmzZnbHOOvMzC4zs7Vm9oKZHZrtesLixP3n8F9ffC/zypOcd/1T/PTBtZo3EJFxzUSP4FJg9U7WnQIsCx4XAlfOQD2hsaS2hN9efAynvms+/3r3y1z8q2fo6h/MdVkiMstkNQjMrB44Dbh2J5ucBfzCM54AKs1Md1+ZRqmiGJd/6j1889QD+OOqrZx1xaO6lLWIvE22ewQ/Ar4G7OwO7AuBjaNebwqWvY2ZXWhmK8xsRXOzxrsny8z46+OXctMFR9LWk+bMKx7jjhc257osEZklshYEZnY60OTuK3e12TjL3jGQ7e5Xu3ujuzfW1dVNW41hc8w+tdz5pePYf14ZX7z5Wb5z+yr60jrEVCTsstkjOBY408zWA7cCJ5nZTWO22QQsGvW6HtCfqlk0ryLJrRcezeeOXcLPH1/PGZc/yotvtue6LBHJoawFgbt/w93r3X0JcDZwv7ufO2az24HPBkcPHQW0u7uukZBlRbEI3z7jIG78qyNo703zFz99jMvve5X+QfUORMJoxs8jMLOLzOyi4OVdwDpgLXANcPFM1xNm79u3jj9++XhOPmge//6nV/jQDx/m/jXbcl2WiMwwy7djyxsbG33FihW5LqPgPPRKM9/9r1Wsa+7mhP3q+OqH9uOgBRW5LktEpomZrXT3xvHW6cxiATK9g7svPZ5vnnoAz2zYwWmXPcolNz/D2qauXJcmIlmmHoG8Q3tvmmsfWcf1j75OT3qIUw+ezxdO2JuDF6qHIJKvdtUjUBDITm3v6ue6R1/nl3/eQGf/IMctq+UzRzVw0v5ziEXVmRTJJwoCmZKOvjS/euINfv7462zr6GdeeZJPHL6IM949n33mlGI23ukgIjKbKAhkWgwODXPfmiZufvINHn61GXdYWlvChw6exwcOmMMhi6qIRhQKIrORgkCm3baOPu5ZtZU/rtrGn9dtZ2jYqUrFed++dRy1tIbGJdXsXVei3oLILKEgkKxq70nz0KvNPLCmiYdfaWZ79wAAVak4hzVU0bikmsaGKpbNKaMiFc9xtSLhtKsg0B3KZMoqUnHOXL6AM5cvwN1Z19LNivWtrFi/g5UbdnDv6qa3ti1LxqivSrHPnFIOnF/OgQvK2buuhHnlSU1Ai+SIegSSdS1d/TyzYQdvtPawsbWHjTt6eXlrJ2+29b61TSxizK9MsrS2lAPml3PA/DIaakooTcQoS8aoShVRFFNQiOwp9Qgkp2pLE5x80Lx3LG/vSfPSlg7Wb+9m044eNrb2srapi8dfW0d66O1/oEQMFlenWFpXyuLqFLWlRVSXJJhbnmCv2hIWV6fUoxDZQwoCyZmKVJyj967h6L1r3rZ8YHCYtU1dbO3opbNvkO7+Iba29/JaSzevNXXx1Out77jTWixiLKgsJhmPUBSLkCqKsVdNCcvmlrJXbQmpohhFsQjJeIRF1SnKk5qrEBmhIJBZpygW4cAFmfmDnelLD9HaPcCW9j7WNXexrqWbN3f0MjA4zMDQMJ19ae5dvY3/WLFx3PfXlibYqzZFWTJOMh4hGYtSV55gUVWK+qpi5lUkqStNUJUqIqJDYqXAKQgkLyXjURZUFrOgspjDGqp2ul1r9wAbtnfTl84ERE//IG+09rCuuZv127tp6uyjPz1Mz8AQzZ39DAy9/WZ60YhRlSqipqSI6pIi5pQnmFeRZH55kprSBOXFccqSMWpKiphXkSQRi2a76SLTTkEgBa06+AKfiOFhp6mzn407emjq6Ke5s4+mzn5auwfeejz7Rhtb2/veERgjaksz8xZVqSIqUnFqSoqYW55kTlmCurIElakiKovjVJUUUZ6M6TwLmRUUBCKBSMSYV5FkXkVyl9u5O9u7B9jRPUBH3yAdvWlauvrZ0t7H5rZemjr7aesZYHNbLy1d/XT0DY77OWWJGAurMr2aVFGURCxKqijK/Moki6pSLKwqpjgeJRYxYtEI1QoPyRIFgcgkmRm1pQlqSxMT2r4vPcS2jj6aO/tp703T3ptme9cAb7b1smlHD5vb+ugbHKI/PUxX/yDtvemdflZxPMrc8kzvoqYkQXVpESVFUWLRCPFohIriOHPLE8wpS1JRHKcoFiERi1CSiClEZKcUBCJZloxHaagpoaGmZELbd/cPsmlHL2+29TAwOMzgsDMwOExr9wBb2/vY2tHH9q4B1rV08dT6AXoHhhgcHn7HIbdjxSJGZaqI6pI41SVF1JQkqEjFScaiJOOZsBiZC6kuKaIkESNVFCVVFCMZj2R6JzpEtyApCERmmZJEjP3mlbHfvLJJvW942GnvTdPU2c/Wjj66+gYZGPqfnsaOnsw8x/auzM/VWzro6EvTlx6mNz3E0PDuTy4tikaoLS1iTnmS2tIEZpn9OlBTUsT8ymIWVCRJxCOMnKtaloxTW1pEbWmCsmSMZDxKIhZR72QWURCIFIhIxKgqKaKqpGjSIQKZIazt3QO0dg3Q2jNA70DmHI6e9BD96SF6B4boDo6uaurs4822XtydWDTzhb5qcztNnf1M9GIFiWDYKhmPUhz0PFJFUUoSMcoSMUoTMVKJKMl4lGQwf1JeHKMsGac0kTkvJB7NfEYsam89r0oVkSqKKmgmQUEgIkBmCGthZTELK4v3+DMGBodp6uxjcNQwVUdfZjK9pXOArv5B+gaH6EsP058eon9wmL70EL3pIXoGhugZyMyRvLmjh67+TBD1pYcYnEBv5e1tibx1WZJoxIhFjOJRgTNy7kiyKEpFcZzqVBGVqTjuBPsdpLgoytzyJHPLk5QkohiZYCmKZeZiRuZgCoGCQESmTVEsQn1Vato/d3BomJ70EJ3BUVrd/YNvnTw4Mo+SHhqmPz1Ma88A27v62dGTJj00zFCwri89TO/AEE2dffSlgwAaGKK9Nz3poBlRFM2cyT4yKT8yp1KSiFJZnAmX0kTma3bYIRqBylQRVUHwxCJGxIxY1DKBFPToomaMVFQcj2b9Ph8KAhGZ9WLRCOXRCOXJ+JR6LONx98wcSneaSARKEzFKEjF6BjJHe21t76NnYOit7fsHM+HR3pOmayATSKODpmdgkK7+Qda1dNHWk6arfxAjc7TZ0LDTmx7aeTHjMIOK4jiVxXHOPaqBzx+3dFrbDwoCEQk5M6MsGadszPWnKoozQ0D7zp38fMuu9KWHaOtJs6NngKFhZ9id9JDT3jtAa3eatmD5yBRHV/8QbT0DtPWkqSub2CHLk6UgEBGZQcl4lHkV0d2euDiTCmOmQ0RE9piCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQM5/opQJnCTNrBjbs4dtrgZZpLCdfhLHdYWwzhLPdYWwzTL7dDe5eN96KvAuCqTCzFe7emOs6ZloY2x3GNkM42x3GNsP0tltDQyIiIacgEBEJubAFwdW5LiBHwtjuMLYZwtnuMLYZprHdoZojEBGRdwpbj0BERMZQEIiIhFxogsDMPmxmL5vZWjP7eq7ryQYzW2RmD5jZajNbZWaXBsurzexPZvZq8LMq17VONzOLmtmzZnZH8DoMba40s1+b2Zrg3/zokLT774Lf7xfN7BYzSxZau83sejNrMrMXRy3baRvN7BvBd9vLZvahye4vFEFgZlHgJ8ApwIHAp8zswNxWlRWDwFfc/QDgKOCSoJ1fB+5z92XAfcHrQnMpsHrU6zC0+cfA3e6+P7CcTPsLut1mthD4EtDo7gcDUeBsCq/dPwc+PGbZuG0M/h8/GzgoeM9Pg++8CQtFEABHAGvdfZ27DwC3AmfluKZp5+5b3P2Z4HknmS+GhWTaemOw2Y3AR3JSYJaYWT1wGnDtqMWF3uZy4HjgOgB3H3D3Ngq83YEYUGxmMSAFbKbA2u3uDwOtYxbvrI1nAbe6e7+7vw6sJfOdN2FhCYKFwMZRrzcFywqWmS0B3gM8Ccx19y2QCQtgTg5Ly4YfAV8DhkctK/Q2LwWagRuCIbFrzayEAm+3u78J/BvwBrAFaHf3eyjwdgd21sYpf7+FJQhsnGUFe9ysmZUCvwG+7O4dua4nm8zsdKDJ3VfmupYZFgMOBa509/cA3eT/cMhuBePiZwF7AQuAEjM7N7dV5dyUv9/CEgSbgEWjXteT6U4WHDOLkwmBX7n7b4PF28xsfrB+PtCUq/qy4FjgTDNbT2bI7yQzu4nCbjNkfqc3ufuTwetfkwmGQm/3B4DX3b3Z3dPAb4FjKPx2w87bOOXvt7AEwdPAMjPby8yKyEys3J7jmqadmRmZMePV7v6DUatuB84Lnp8H/H6ma8sWd/+Gu9e7+xIy/673u/u5FHCbAdx9K7DRzPYLFr0feIkCbzeZIaGjzCwV/L6/n8xcWKG3G3bextuBs80sYWZ7AcuApyb1ye4eigdwKvAK8BrwzVzXk6U2vpdMl/AF4LngcSpQQ+Yog1eDn9W5rjVL7T8BuCN4XvBtBg4BVgT/3r8DqkLS7u8Ca4AXgV8CiUJrN3ALmTmQNJm/+C/YVRuBbwbfbS8Dp0x2f7rEhIhIyIVlaEhERHZCQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQSamY2ZGbPjXpM29m5ZrZk9NUjJ7B9iZn9KXj+aHAtHZGs0y+ahF2vux+S6yICRwNPBJdR6Hb3wVwXJOGgHoHIOMxsvZn9i5k9FTz2CZY3mNl9ZvZC8HNxsHyumd1mZs8Hj2OCj4qa2TXB9fPvMbPicfa1t5k9B9wEfBpYCSwPeiiFePE0mWUUBBJ2xWOGhj45al2Hux8BXEHmCqcEz3/h7u8GfgVcFiy/DHjI3ZeTuebPqmD5MuAn7n4Q0Ab85dgC3P21oFeykszlg38BXODuh7h7IV4zR2YZnVksoWZmXe5eOs7y9cBJ7r4uuJDfVnevMbMWYL67p4PlW9y91syagXp37x/1GUuAP3nmRiKY2T8AcXf/3k5qedrdDzez3wBf8swll0WyTj0CkZ3znTzf2Tbj6R/1fIhx5uXM7KpgUnlZMET0YeBOM/u7SdQqsscUBCI798lRP/8cPH+czFVOAc4BHg2e3wd8Ad66f3L5RHfi7heRuZDaP5G569SdwbDQD6dUvcgE6aghCbvi4K/wEXe7+8ghpAkze5LMH0yfCpZ9CbjezL5K5g5hnwuWXwpcbWYXkPnL/wtkrh45Ue8jMzdwHPDQnjREZE9pjkBkHMEcQaO7t+S6FpFs09CQiEjIqUcgIhJy6hGIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjI/X+WwnM74wmBAwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "([6.149310831251091,\n",
              "  6.00003963875371,\n",
              "  5.93023366235488,\n",
              "  5.852135088190686,\n",
              "  5.716434159092397,\n",
              "  5.431633634940206,\n",
              "  5.01822709238063,\n",
              "  4.709834477088971,\n",
              "  4.594547037305778,\n",
              "  4.5475304033503186,\n",
              "  4.467332211286662,\n",
              "  4.4060330950348074,\n",
              "  4.354358737029177,\n",
              "  4.308325613011195,\n",
              "  4.261422141304229,\n",
              "  4.215657196897368,\n",
              "  4.171845334868191,\n",
              "  4.131626022594601,\n",
              "  4.095990399408607,\n",
              "  4.0631084335582885,\n",
              "  4.032255375185493,\n",
              "  4.00139912013901,\n",
              "  3.97116165587356,\n",
              "  3.9440588072025577,\n",
              "  3.9211655515532255,\n",
              "  3.900874430906839,\n",
              "  3.8825079209311713,\n",
              "  3.8667701849058354,\n",
              "  3.8542876003840782,\n",
              "  3.842838862754779,\n",
              "  3.833793128668929,\n",
              "  3.824743601196971,\n",
              "  3.8198405857192737,\n",
              "  3.812527960239176,\n",
              "  3.807616803899158,\n",
              "  3.8003909574540633,\n",
              "  3.7982647858518463,\n",
              "  3.7921840305434924,\n",
              "  3.7889312232672836,\n",
              "  3.78293524374509,\n",
              "  3.781890229805888,\n",
              "  3.775570533795064,\n",
              "  3.774533490228919,\n",
              "  3.7686589416844885,\n",
              "  3.76733530566679,\n",
              "  3.762422614923403,\n",
              "  3.7587774692300977,\n",
              "  3.755652102678182,\n",
              "  3.7513764450669953,\n",
              "  3.7489949231707183,\n",
              "  3.7444940492427548,\n",
              "  3.7416851533857804,\n",
              "  3.737700563569309,\n",
              "  3.735042422843379,\n",
              "  3.730104840667554,\n",
              "  3.728817731974511,\n",
              "  3.7237948625447364,\n",
              "  3.723174409493388,\n",
              "  3.7191496694554163,\n",
              "  3.7157687821201772,\n",
              "  3.714936155180691,\n",
              "  3.7110146890139446,\n",
              "  3.7098983679403807,\n",
              "  3.706819544957337,\n",
              "  3.703636382545173,\n",
              "  3.7022615997484944,\n",
              "  3.6989554719551982,\n",
              "  3.6971704493687807,\n",
              "  3.6957544081703912,\n",
              "  3.6918559580541856,\n",
              "  3.6923401475618673,\n",
              "  3.6878516341054906,\n",
              "  3.6879189773644816,\n",
              "  3.684455914204347,\n",
              "  3.683075420017349,\n",
              "  3.681796196452732,\n",
              "  3.680044419272652,\n",
              "  3.677879035139883,\n",
              "  3.6765032294076248,\n",
              "  3.6741177010136608,\n",
              "  3.67314369585261,\n",
              "  3.6722983674630107,\n",
              "  3.669035245586374,\n",
              "  3.6684389593880935,\n",
              "  3.666767397406381,\n",
              "  3.6653544250147303,\n",
              "  3.6623051819188635,\n",
              "  3.664341889280181,\n",
              "  3.6602981823116707,\n",
              "  3.6602940053247206,\n",
              "  3.6576718378333406,\n",
              "  3.6566283582975077,\n",
              "  3.6549275574071447,\n",
              "  3.652164096938831,\n",
              "  3.65236331364296,\n",
              "  3.6492995789597154,\n",
              "  3.6489089454352523,\n",
              "  3.6458030572816646,\n",
              "  3.6459523206316558,\n",
              "  3.64318979785429],\n",
              " [0.10754189944134078,\n",
              "  0.10474860335195531,\n",
              "  0.10474860335195531,\n",
              "  0.10474860335195531,\n",
              "  0.10474860335195531,\n",
              "  0.10195530726256984,\n",
              "  0.08798882681564246,\n",
              "  0.07402234636871509,\n",
              "  0.07262569832402235,\n",
              "  0.08519553072625698,\n",
              "  0.08659217877094973,\n",
              "  0.09636871508379888,\n",
              "  0.11452513966480447,\n",
              "  0.14106145251396648,\n",
              "  0.1452513966480447,\n",
              "  0.1494413407821229,\n",
              "  0.15782122905027932,\n",
              "  0.15921787709497207,\n",
              "  0.15782122905027932,\n",
              "  0.1634078212290503,\n",
              "  0.16759776536312848,\n",
              "  0.17039106145251395,\n",
              "  0.1717877094972067,\n",
              "  0.17737430167597765,\n",
              "  0.1829608938547486,\n",
              "  0.1871508379888268,\n",
              "  0.18435754189944134,\n",
              "  0.1871508379888268,\n",
              "  0.18854748603351956,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.1941340782122905,\n",
              "  0.1941340782122905,\n",
              "  0.1941340782122905,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.1941340782122905,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.19553072625698323,\n",
              "  0.19273743016759776,\n",
              "  0.1941340782122905,\n",
              "  0.19273743016759776,\n",
              "  0.19273743016759776,\n",
              "  0.1941340782122905,\n",
              "  0.19134078212290503,\n",
              "  0.19134078212290503,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.1871508379888268,\n",
              "  0.19134078212290503,\n",
              "  0.18854748603351956,\n",
              "  0.19134078212290503,\n",
              "  0.1871508379888268,\n",
              "  0.18854748603351956,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.18854748603351956,\n",
              "  0.19134078212290503,\n",
              "  0.18854748603351956,\n",
              "  0.18994413407821228,\n",
              "  0.19134078212290503,\n",
              "  0.18994413407821228,\n",
              "  0.19273743016759776,\n",
              "  0.18994413407821228,\n",
              "  0.19134078212290503,\n",
              "  0.19134078212290503,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.19273743016759776,\n",
              "  0.18994413407821228,\n",
              "  0.19134078212290503,\n",
              "  0.19273743016759776,\n",
              "  0.18994413407821228,\n",
              "  0.18994413407821228,\n",
              "  0.19273743016759776,\n",
              "  0.18854748603351956,\n",
              "  0.19134078212290503,\n",
              "  0.19273743016759776,\n",
              "  0.18994413407821228,\n",
              "  0.19273743016759776,\n",
              "  0.18994413407821228,\n",
              "  0.19134078212290503,\n",
              "  0.18994413407821228,\n",
              "  0.18854748603351956,\n",
              "  0.19273743016759776,\n",
              "  0.18994413407821228,\n",
              "  0.19273743016759776,\n",
              "  0.18994413407821228,\n",
              "  0.19134078212290503,\n",
              "  0.18854748603351956,\n",
              "  0.19134078212290503])"
            ]
          },
          "execution_count": 1246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Network()\n",
        "train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnlPqDXZnjmG"
      },
      "source": [
        "### Deprecated code for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w53TbXOnjmH"
      },
      "source": [
        "Examine weights at every layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQouvNexnjmH",
        "outputId": "944ee39a-7458-4775-a616-4c61d6413ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 5]) torch.Size([5])\n",
            "tensor([[2.6562, 3.7774, 0.3459, 1.2566, 0.0000],\n",
            "        [1.6194, 2.9163, 0.0000, 0.8579, 0.0000],\n",
            "        [1.1465, 0.0000, 0.0000, 0.6298, 0.4821],\n",
            "        [1.4496, 4.4364, 0.0000, 1.0822, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [1.6923, 0.5277, 0.0000, 1.1399, 0.6488],\n",
            "        [1.9688, 5.2606, 0.0000, 1.1872, 0.0000],\n",
            "        [1.4789, 4.2494, 1.1399, 0.9333, 0.0000],\n",
            "        [0.0000, 0.0000, 3.3393, 0.0000, 1.6777],\n",
            "        [1.4936, 3.9115, 0.0000, 1.0701, 0.0000]], grad_fn=<ReluBackward0>) \n",
            "\n",
            "  tensor([[1.5944, 0.0000, 0.0000, 2.2556, 0.0000],\n",
            "        [1.7080, 0.0000, 0.0000, 1.6231, 0.0000],\n",
            "        [1.6067, 1.7206, 0.0000, 0.2798, 0.0000],\n",
            "        [1.6616, 0.0000, 0.0000, 2.1532, 0.0000],\n",
            "        [1.6646, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [1.6118, 1.8190, 0.0000, 0.6776, 0.0000],\n",
            "        [1.6538, 0.0000, 0.0000, 2.6651, 0.0000],\n",
            "        [1.0944, 0.0000, 0.0000, 1.8052, 0.0000],\n",
            "        [0.0000, 3.6739, 0.0000, 0.0000, 0.0000],\n",
            "        [1.6876, 0.0000, 0.0000, 1.9652, 0.0000]], grad_fn=<ReluBackward0>) \n",
            "\n",
            " tensor([[ 2.5092,  2.2002,  3.3305,  2.4930,  2.1255,  3.3039,  2.0523],\n",
            "        [ 2.3738,  2.1171,  3.0749,  2.3419,  2.0558,  2.9915,  1.9177],\n",
            "        [-0.6906, -0.1610, -0.7297, -0.4851, -0.9122, -0.3108, -0.7055],\n",
            "        [ 2.5206,  2.2119,  3.3258,  2.5013,  2.1451,  3.2947,  2.0496],\n",
            "        [ 1.7975,  1.7309,  2.1674,  1.7290,  1.6648,  1.9054,  1.4412],\n",
            "        [-0.6986, -0.1792, -0.6833, -0.4687, -0.9687, -0.1836, -0.7169],\n",
            "        [ 2.6877,  2.3227,  3.5959,  2.6802,  2.2549,  3.6191,  2.1915],\n",
            "        [ 2.0156,  1.8409,  2.7117,  1.9948,  1.7079,  2.5881,  1.7288],\n",
            "        [-4.7700, -3.2386, -5.4994, -4.2494, -4.9475, -4.5216, -3.9157],\n",
            "        [ 2.4751,  2.1832,  3.2440,  2.4512,  2.1195,  3.1953,  2.0066]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "f1, f2, f3, s1, s2, s3 = model(X_train[0:10])\n",
        "\n",
        "print(f1.shape, s1.shape)\n",
        "print(f\"{f1} \\n\\n  {f2} \\n\\n {f3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGczq0N_njmH"
      },
      "source": [
        "Figure out how to compute accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k74e3kwUnjmH",
        "outputId": "8da8ae01-2921-46f6-f708-12b94b0b33f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [3., 4., 4.]]) tensor([[3., 0.]])\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "predicted = torch.Tensor([[1, 2, 3], [3, 4, 4]])\n",
        "\n",
        "true = torch.Tensor([[3, 0]])\n",
        "    \n",
        "print(predicted, true)\n",
        "print(np.array(torch.argmax(predicted, dim=1) + 1 == true).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnzcV0AKnjmJ"
      },
      "source": [
        "Previous attempts at defining companion loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42u_YSnKnjmJ",
        "outputId": "9077d2a5-1b60-4946-8bac-54fb483e854d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nfor row in f_labels:\\n    svm_pred = torch.unsqueeze(f_map @ svm_w, dim=0).T # shape = (# examples, 1)\\n    row = torch.unsqueeze(row, dim=0) # shape = (1, 6)\\n    f_label_svms = svm_pred.long() @ row\\n    loss += torch.sum(torch.nn.functional.relu(1 - (true_label_svm.T - f_label_svms))**2)\\nreturn loss\\n    #true_label_svm = torch.unsqueeze((f_map @ svm_w) * t_labels, dim=0).T # torch.Size([716, 1]) \\n'"
            ]
          },
          "execution_count": 603,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "deprecated code -- alternate ways I tried calculating loss\n",
        "i = 0\n",
        "for row in f_labels: # i.e. row = torch.Tensor([0, 2, 3, 4, 5, 6])\n",
        "    i += 1\n",
        "    if i % 10 == 0:\n",
        "        print(i)\n",
        "    for f_label in row:\n",
        "        # < w^(m), (Z^(m), y_k) >\n",
        "        f_label_svm = (f_map @ svm_w) * f_label\n",
        "\n",
        "        # max(0, 1 - (true_label_svm - f_label_svm))**2\n",
        "        loss += sum(torch.nn.functional.relu(1 - (true_label_svm - f_label_svm))**2)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "for row in f_labels:\n",
        "    svm_pred = torch.unsqueeze(f_map @ svm_w, dim=0).T # shape = (# examples, 1)\n",
        "    row = torch.unsqueeze(row, dim=0) # shape = (1, 6)\n",
        "    f_label_svms = svm_pred.long() @ row\n",
        "    loss += torch.sum(torch.nn.functional.relu(1 - (true_label_svm.T - f_label_svms))**2)\n",
        "return loss\n",
        "    #true_label_svm = torch.unsqueeze((f_map @ svm_w) * t_labels, dim=0).T # torch.Size([716, 1]) \n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvlU3JmnnjmJ"
      },
      "source": [
        "Examining initial loss values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGfxDjv_njmK",
        "outputId": "2b44256a-60c5-4053-9460-996c6d41230d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5558.4961, grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 1237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test loss\n",
        "\n",
        "f1, f2, f3, svm1, svm2, svm3 = model(X_train)\n",
        "\n",
        "loss_1 = companion_loss(f1, svm1, Y_train)\n",
        "loss_2 = companion_loss(f2, svm2, Y_train)\n",
        "loss_3 = companion_loss(f3, svm3, Y_train)\n",
        "\n",
        "global_loss(model(X_train), Y_train, alphas=[0.1, 0.2, 0.3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COYOP_RsnjmK"
      },
      "source": [
        "Get familiar with re-shaping of input needed in loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4W1vbN7njmK",
        "outputId": "cea01659-d792-4a9c-ce73-7d0cf4b02e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 9]) torch.Size([1, 3]) torch.Size([1, 9])\n",
            "tensor([[  0.,  -1.,   2.],\n",
            "        [  0.,  -2.,   4.],\n",
            "        [  0.,  -3.,   6.],\n",
            "        [  0.,  -4.,   8.],\n",
            "        [  0.,  -5.,  10.],\n",
            "        [  0.,  -6.,  12.],\n",
            "        [  0.,  -7.,  14.],\n",
            "        [  0.,  -8.,  16.],\n",
            "        [  0., -10.,  20.]]) torch.Size([9, 3])\n",
            "tensor([[  0.,  -1.,   2.],\n",
            "        [  0.,  -2.,   4.],\n",
            "        [  0.,  -3.,   6.],\n",
            "        [  0.,  -4.,   8.],\n",
            "        [  0.,  -5.,  10.],\n",
            "        [  0.,  -6.,  12.],\n",
            "        [  0.,  -7.,  14.],\n",
            "        [  0.,  -8.,  16.],\n",
            "        [  0., -10.,  20.]])\n",
            "tensor([   0.,    0., 1216.])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Re-shaping is needed in companion_loss() because in class Network.forward(), svm weights are defined to be 1 dimension i.e. (#dim,) instead of (#dim,1).\n",
        "We didn't realize this before, so we did re-shaping of svm weights in the loss function.  Properly defining weights in the forward() could work, but then we'd have to\n",
        "change up the re-shaping stuff in the loss function\n",
        "\"\"\"\n",
        "\n",
        "a = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 10])\n",
        "a = torch.unsqueeze(a, dim=0)\n",
        "\n",
        "true = torch.ones(a.shape)\n",
        "\n",
        "f = torch.Tensor([0, -1, 2])\n",
        "f = torch.unsqueeze(f, dim=0)\n",
        "\n",
        "m = (a.T @ f)\n",
        "\n",
        "print(a.shape, f.shape, true.shape)\n",
        "print(m, m.shape)\n",
        "print(1 - (true.T - m))\n",
        "print(sum(torch.nn.functional.relu(1 - (true.T - m))**2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfgQ8UUdnjmK"
      },
      "source": [
        "Broadcasting multiplication of the vector of predicted svm values and the 6 vectors of false labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y60WFMN5njmK",
        "outputId": "f9b68fdc-3d60-42ff-f8fc-0bba7183e797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([9, 1]) torch.Size([9, 3])\n",
            "tensor([[ 1.],\n",
            "        [ 2.],\n",
            "        [ 3.],\n",
            "        [ 4.],\n",
            "        [ 5.],\n",
            "        [ 6.],\n",
            "        [ 7.],\n",
            "        [ 8.],\n",
            "        [10.]])\n",
            "tensor([[ 1.,  1.,  1.],\n",
            "        [ 2.,  2.,  2.],\n",
            "        [ 3.,  3.,  3.],\n",
            "        [ 4.,  4.,  4.],\n",
            "        [ 5.,  5.,  5.],\n",
            "        [ 6.,  6.,  6.],\n",
            "        [ 7.,  7.,  7.],\n",
            "        [ 8.,  8.,  8.],\n",
            "        [10., 10., 10.]])\n",
            "tensor([[  1.,   1.,   1.],\n",
            "        [  4.,   4.,   4.],\n",
            "        [  9.,   9.,   9.],\n",
            "        [ 16.,  16.,  16.],\n",
            "        [ 25.,  25.,  25.],\n",
            "        [ 36.,  36.,  36.],\n",
            "        [ 49.,  49.,  49.],\n",
            "        [ 64.,  64.,  64.],\n",
            "        [100., 100., 100.]])\n"
          ]
        }
      ],
      "source": [
        "j = torch.cat([a] * 3, dim=0) #.squeeze(dim=1)\n",
        "\n",
        "print(a.T.shape, j.T.shape)\n",
        "\n",
        "print(a.T)\n",
        "print(j.T)\n",
        "print(a.T * j.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwtbnCXpnjmL",
        "outputId": "0f3b22bb-b16d-4ef9-be8e-abc561d333e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[-3.5995e+09, -7.1990e+09],\n",
              "        [-4.6115e+09, -9.2229e+09],\n",
              "        [-1.0095e+10, -2.0191e+10],\n",
              "        ...,\n",
              "        [-3.0495e+09, -6.0990e+09],\n",
              "        [-3.0662e+09, -6.1324e+09],\n",
              "        [-4.7045e+09, -9.4091e+09]], grad_fn=<MmBackward0>)"
            ]
          },
          "execution_count": 460,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm_w = torch.randn(f1.shape[1])\n",
        "\n",
        "g = f1 @ svm_w\n",
        "g = torch.unsqueeze(g, dim=0).T\n",
        "\n",
        "print(torch.unsqueeze(torch.Tensor([1, 2, 3]), dim=0).shape)\n",
        "\n",
        "g @ torch.unsqueeze(torch.Tensor([1, 2]), dim=0)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a209b2a29af6db15caeb87b5a469aa1eed57ecd42970a9baa7e0ed0c9978c8fe"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "DSN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}